<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training a Sequence Labeler &mdash; NL-FM-Toolkit  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Training a Sequence Classifier" href="sequence_classifier_train.html" />
    <link rel="prev" title="Training a Causal Language Model from Scratch" href="clm_train.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> NL-FM-Toolkit
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_train.html">Training a Tokenizer from Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="tokenizer_train.html#creating-model-configuration-file">Creating Model Configuration File</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlm_train.html">Training a Masked Language Model from Scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="clm_train.html">Training a Causal Language Model from Scratch</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training a Sequence Labeler</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#convert-conll-file-to-json-format">Convert CoNLL file to JSON format</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-a-token-classifier">Training a Token classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hyper-parameter-tuning">Hyper-Parameter Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fine-tuning-using-best-hyper-parameter">Fine-Tuning using best Hyper-Parameter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sequence_classifier_train.html">Training a Sequence Classifier</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scripts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules/index.html">Modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NL-FM-Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Training a Sequence Labeler</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/token_classifier_train.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="training-a-sequence-labeler">
<h1>Training a Sequence Labeler<a class="headerlink" href="#training-a-sequence-labeler" title="Permalink to this heading"></a></h1>
<p>Let us now look into a short tutorial on training a sequence labeler (token classifier) using pre-trained language model.</p>
<p>For this tutorial, we provide a sample corpus in the folder <code class="docutils literal notranslate"><span class="pre">demo/data/ner/en/</span></code>. The data is taken from WikiANN-NER <a class="reference external" href="https://huggingface.co/datasets/wikiann">https://huggingface.co/datasets/wikiann</a></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp"> $ </span>ls demo/data/ner/
<span class="linenos">2</span><span class="go"> en</span>
<span class="linenos">3</span>
<span class="linenos">4</span><span class="gp"> $ </span>ls demo/data/ner/en/
<span class="linenos">5</span><span class="go"> dev.csv</span>
<span class="linenos">6</span><span class="go"> test.csv</span>
<span class="linenos">7</span><span class="go"> train.csv</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">dev</span></code>, and <code class="docutils literal notranslate"><span class="pre">test</span></code> files are in conll format. The sample snippet of the train corpus is here</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="gp"> $ </span>cat demo/data/ner/en/train.csv
<span class="linenos"> 2</span><span class="go"> This        O</span>
<span class="linenos"> 3</span><span class="go"> is  O</span>
<span class="linenos"> 4</span><span class="go"> not O</span>
<span class="linenos"> 5</span><span class="go"> Romeo       B-PER</span>
<span class="linenos"> 6</span><span class="go"> ,   O</span>
<span class="linenos"> 7</span><span class="go"> he’s        O</span>
<span class="linenos"> 8</span><span class="go"> some        O</span>
<span class="linenos"> 9</span><span class="go"> other       O</span>
<span class="linenos">10</span><span class="go"> where.      O</span>
<span class="linenos">11</span>
<span class="linenos">12</span><span class="go"> Your        O</span>
<span class="linenos">13</span><span class="go"> plantain    O</span>
<span class="linenos">14</span><span class="go"> leaf        O</span>
<span class="linenos">15</span><span class="go"> is  O</span>
<span class="linenos">16</span><span class="go"> excellent   O</span>
<span class="linenos">17</span><span class="go"> for O</span>
<span class="linenos">18</span><span class="go"> that.       O</span>
</pre></div>
</div>
<p>Every word is present in it’s own file followed by either a <code class="docutils literal notranslate"><span class="pre">space</span></code> or a <code class="docutils literal notranslate"><span class="pre">tab</span></code> followed by the entity label. Successive sentences are separated by an empty line.</p>
<p>The filenames should be the same as mentioned above</p>
<section id="convert-conll-file-to-json-format">
<h2>Convert CoNLL file to JSON format<a class="headerlink" href="#convert-conll-file-to-json-format" title="Permalink to this heading"></a></h2>
<p>We need to convert the CoNLL file to JSON format so that we can easily load the model and perform training. We use the following script to perform the conversion.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>python src/tokenclassifier/helper_scripts/conll_to_json_converter.py <span class="se">\</span>
<span class="linenos">2</span>    --data_dir &lt;path to folder containing CoNLL files&gt; <span class="se">\</span>
<span class="linenos">3</span>    --column_number &lt;column number containing the labels&gt;
</pre></div>
</div>
<p>For our example, we run the following command</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>python src/tokenclassifier/helper_scripts/conll_to_json_converter.py <span class="se">\</span>
<span class="linenos">2</span>    --data_dir demo/data/ner/en/ <span class="se">\</span>
<span class="linenos">3</span>    --column_number <span class="m">1</span>
</pre></div>
</div>
</section>
<section id="training-a-token-classifier">
<h2>Training a Token classifier<a class="headerlink" href="#training-a-token-classifier" title="Permalink to this heading"></a></h2>
<p>We could directly train a token classifier by specifying the hyper-parameters as follows</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="gp">$ </span>python src/tokenclassifier/train_tc.py <span class="se">\</span>
<span class="linenos"> 2</span>    --data &lt;path to data folder/huggingface dataset name&gt; <span class="se">\</span>
<span class="linenos"> 3</span>    --model_name &lt;model name or path&gt; <span class="se">\</span>
<span class="linenos"> 4</span>    --tokenizer_name &lt;Tokenizer name or path&gt; <span class="se">\</span>
<span class="linenos"> 5</span>    --task_name &lt;ner or pos&gt; <span class="se">\</span>
<span class="linenos"> 6</span>    --output_dir &lt;output folder where the model will be saved&gt; <span class="se">\</span>
<span class="linenos"> 7</span>    --batch_size &lt;batch size to be used&gt; <span class="se">\</span>
<span class="linenos"> 8</span>    --learning_rate &lt;learning rate to be used&gt; <span class="se">\</span>
<span class="linenos"> 9</span>    --train_steps &lt;maximum number of training steps&gt; <span class="se">\</span>
<span class="linenos">10</span>    --eval_steps &lt;steps after which evaluation on dev <span class="nb">set</span> is performed&gt; <span class="se">\</span>
<span class="linenos">11</span>    --save_steps &lt;steps after which the model is saved&gt; <span class="se">\</span>
<span class="linenos">12</span>    --config_name &lt;configuration name&gt; <span class="se">\</span>
<span class="linenos">13</span>    --max_seq_len &lt;Maximum Sequence Length after which the sequence is trimmed&gt; <span class="se">\</span>
<span class="linenos">14</span>    --perform_grid_search &lt;Perform grid search where only the result would be stored&gt; <span class="se">\</span>
<span class="linenos">15</span>    --seed &lt;random seed used&gt; <span class="se">\</span>
<span class="linenos">16</span>    --eval_only &lt;Perform evaluation only&gt;
</pre></div>
</div>
</section>
<section id="hyper-parameter-tuning">
<h2>Hyper-Parameter Tuning<a class="headerlink" href="#hyper-parameter-tuning" title="Permalink to this heading"></a></h2>
<p>We first have to select the best hyper-parameter value. For this, we monitor the loss/accuracy/f1-score on the dev set and select the best hyper-parameter. We perform a grid-search over <code class="docutils literal notranslate"><span class="pre">batch</span> <span class="pre">size</span></code> and <code class="docutils literal notranslate"><span class="pre">learning</span> <span class="pre">rate</span></code> only.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 19%" />
<col style="width: 81%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Hyper-Parameter</p></th>
<th class="head"><p>Values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Batch Size</p></td>
<td><p>8, 16, 32</p></td>
</tr>
<tr class="row-odd"><td><p>Learning Rate</p></td>
<td><p>1e-3, 1e-4, 1e-5, 1e-6, 3e-3, 3e-4, 3e-5, 13e-6, 5e-3, 5e-4, 5e-5, 5e-6</p></td>
</tr>
</tbody>
</table>
<p>We now perform hyper-parameter tuning of the sequence labeler</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>python src/tokenclassifier/helper_scripts/tune_hyper_parameter.py <span class="se">\</span>
<span class="linenos">2</span>    --data_dir demo/data/ner/en/ <span class="se">\</span>
<span class="linenos">3</span>    --configuration_name bert-custom <span class="se">\</span>
<span class="linenos">4</span>    --model_name demo/model/mlm/checkpoint-200/ <span class="se">\</span>
<span class="linenos">5</span>    --output_dir demo/model/ner/en/ <span class="se">\</span>
<span class="linenos">6</span>    --tokenizer_name demo/model/tokenizer/ <span class="se">\</span>
<span class="linenos">7</span>    --log_dir logs
</pre></div>
</div>
<p>The code performs hyper-parameter tuning and <cite>Aim</cite> library tracks the experiment in <code class="docutils literal notranslate"><span class="pre">logs</span></code> folder</p>
</section>
<section id="fine-tuning-using-best-hyper-parameter">
<h2>Fine-Tuning using best Hyper-Parameter<a class="headerlink" href="#fine-tuning-using-best-hyper-parameter" title="Permalink to this heading"></a></h2>
<p>We now run the script <code class="docutils literal notranslate"><span class="pre">src/tokenclassifier/helper_scripts/get_best_hyper_parameter_and_train.py</span></code> to find the best hyper-parameter and fine-tune the model using that best hyper-parameter</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="gp">$ </span>python src/tokenclassifier/helper_scripts/get_best_hyper_parameter_and_train.py <span class="se">\</span>
<span class="linenos"> 2</span>    --data_dir demo/data/ner/en/ <span class="se">\</span>
<span class="linenos"> 3</span>    --configuration_name bert-custom <span class="se">\</span>
<span class="linenos"> 4</span>    --model_name demo/model/mlm/checkpoint-200/ <span class="se">\</span>
<span class="linenos"> 5</span>    --output_dir demo/model/ner/en/ <span class="se">\</span>
<span class="linenos"> 6</span>    --tokenizer_name demo/model/tokenizer/ <span class="se">\</span>
<span class="linenos"> 7</span>    --log_dir logs
<span class="linenos"> 8</span>
<span class="linenos"> 9</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">10</span><span class="go">    |    |   F1-Score |   BatchSize |   LearningRate |</span>
<span class="linenos">11</span><span class="go">    +====+============+=============+================+</span>
<span class="linenos">12</span><span class="go">    |  0 |  0         |          16 |         0.001  |</span>
<span class="linenos">13</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">14</span><span class="go">    |  1 |  0.08      |          16 |         0.0001 |</span>
<span class="linenos">15</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">16</span><span class="go">    |  2 |  0.0833333 |          16 |         1e-05  |</span>
<span class="linenos">17</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">18</span><span class="go">    |  3 |  0.0833333 |          16 |         1e-06  |</span>
<span class="linenos">19</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">20</span><span class="go">    |  4 |  0         |          16 |         0.003  |</span>
<span class="linenos">21</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">22</span><span class="go">    |  5 |  0         |          16 |         0.0003 |</span>
<span class="linenos">23</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">24</span><span class="go">    |  6 |  0.0833333 |          16 |         3e-05  |</span>
<span class="linenos">25</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">26</span><span class="go">    |  7 |  0.0833333 |          16 |         3e-06  |</span>
<span class="linenos">27</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">28</span><span class="go">    |  8 |  0         |          16 |         0.005  |</span>
<span class="linenos">29</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">30</span><span class="go">    |  9 |  0         |          16 |         0.0005 |</span>
<span class="linenos">31</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">32</span><span class="go">    | 10 |  0.0833333 |          16 |         5e-05  |</span>
<span class="linenos">33</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">34</span><span class="go">    | 11 |  0.0833333 |          16 |         5e-06  |</span>
<span class="linenos">35</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">36</span><span class="go">    | 12 |  0         |          32 |         0.001  |</span>
<span class="linenos">37</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">38</span><span class="go">    | 13 |  0.08      |          32 |         0.0001 |</span>
<span class="linenos">39</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">40</span><span class="go">    | 14 |  0.0833333 |          32 |         1e-05  |</span>
<span class="linenos">41</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">42</span><span class="go">    | 15 |  0.0833333 |          32 |         1e-06  |</span>
<span class="linenos">43</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">44</span><span class="go">    | 16 |  0         |          32 |         0.003  |</span>
<span class="linenos">45</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">46</span><span class="go">    | 17 |  0         |          32 |         0.0003 |</span>
<span class="linenos">47</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">48</span><span class="go">    | 18 |  0.0833333 |          32 |         3e-05  |</span>
<span class="linenos">49</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">50</span><span class="go">    | 19 |  0.0833333 |          32 |         3e-06  |</span>
<span class="linenos">51</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">52</span><span class="go">    | 20 |  0         |          32 |         0.005  |</span>
<span class="linenos">53</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">54</span><span class="go">    | 21 |  0         |          32 |         0.0005 |</span>
<span class="linenos">55</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">56</span><span class="go">    | 22 |  0.0833333 |          32 |         5e-05  |</span>
<span class="linenos">57</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">58</span><span class="go">    | 23 |  0.0833333 |          32 |         5e-06  |</span>
<span class="linenos">59</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">60</span><span class="go">    | 24 |  0         |           8 |         0.001  |</span>
<span class="linenos">61</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">62</span><span class="go">    | 25 |  0.08      |           8 |         0.0001 |</span>
<span class="linenos">63</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">64</span><span class="go">    | 26 |  0.0833333 |           8 |         1e-05  |</span>
<span class="linenos">65</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">66</span><span class="go">    | 27 |  0.0833333 |           8 |         1e-06  |</span>
<span class="linenos">67</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">68</span><span class="go">    | 28 |  0         |           8 |         0.003  |</span>
<span class="linenos">69</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">70</span><span class="go">    | 29 |  0         |           8 |         0.0003 |</span>
<span class="linenos">71</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">72</span><span class="go">    | 30 |  0.0833333 |           8 |         3e-05  |</span>
<span class="linenos">73</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">74</span><span class="go">    | 31 |  0.0833333 |           8 |         3e-06  |</span>
<span class="linenos">75</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">76</span><span class="go">    | 32 |  0         |           8 |         0.005  |</span>
<span class="linenos">77</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">78</span><span class="go">    | 33 |  0         |           8 |         0.0005 |</span>
<span class="linenos">79</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">80</span><span class="go">    | 34 |  0.0833333 |           8 |         5e-05  |</span>
<span class="linenos">81</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">82</span><span class="go">    | 35 |  0.0833333 |           8 |         5e-06  |</span>
<span class="linenos">83</span><span class="go">    +----+------------+-------------+----------------+</span>
<span class="linenos">84</span><span class="go">    Model is demo/model/mlm/checkpoint-200/</span>
<span class="linenos">85</span><span class="go">    Best Configuration is 16 1e-05</span>
<span class="linenos">86</span><span class="go">    Best F1 is 0.08333333333333334</span>
</pre></div>
</div>
<p>The command fine-tunes the model for <code class="docutils literal notranslate"><span class="pre">5</span></code> different random seeds. The models can be found in the folder <code class="docutils literal notranslate"><span class="pre">demo/model/ner/en/</span></code>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>$ ls -lh demo/model/ner/en/ | grep &#39;^d&#39; | awk &#39;{print $9}
<span class="linenos">2</span>bert-custom-model_ner_16_1e-05_4_1
<span class="linenos">3</span>bert-custom-model_ner_16_1e-05_4_2
<span class="linenos">4</span>bert-custom-model_ner_16_1e-05_4_3
<span class="linenos">5</span>bert-custom-model_ner_16_1e-05_4_4
<span class="linenos">6</span>bert-custom-model_ner_16_1e-05_4_5
</pre></div>
</div>
<p>The folder contains the following files</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="gp">$ </span>ls -lh demo/model/ner/en/bert-custom-model_ner_16_1e-05_4_1/ <span class="p">|</span> awk <span class="s1">&#39;{print $5, $9}&#39;</span>
<span class="linenos"> 2</span><span class="go">224B GOAT</span>
<span class="linenos"> 3</span><span class="go">884B config.json</span>
<span class="linenos"> 4</span><span class="go">417B dev_predictions.txt</span>
<span class="linenos"> 5</span><span class="go">188B dev_results.txt</span>
<span class="linenos"> 6</span><span class="go">3.6M pytorch_model.bin</span>
<span class="linenos"> 7</span><span class="go">96B runs</span>
<span class="linenos"> 8</span><span class="go">262B test_predictions.txt</span>
<span class="linenos"> 9</span><span class="go">169B test_results.txt</span>
<span class="linenos">10</span><span class="go">2.9K training_args.bin</span>
</pre></div>
</div>
<p>The files <code class="docutils literal notranslate"><span class="pre">test_predictions.txt</span></code> and <code class="docutils literal notranslate"><span class="pre">dev_predictions.txt</span></code> contains the predictions from the model on <code class="docutils literal notranslate"><span class="pre">test</span></code> and <code class="docutils literal notranslate"><span class="pre">dev</span></code> set respectively.
Similarly, the files <code class="docutils literal notranslate"><span class="pre">test_results.txt</span></code> and <code class="docutils literal notranslate"><span class="pre">dev_results.txt</span></code> contains the results (F1-Score, Accuracy, etc) from the model on <code class="docutils literal notranslate"><span class="pre">test</span></code> and <code class="docutils literal notranslate"><span class="pre">dev</span></code> set respectively.</p>
<p>The sample snippet of the <code class="docutils literal notranslate"><span class="pre">test_predictions.txt</span></code> and <code class="docutils literal notranslate"><span class="pre">dev_predictions.txt</span></code> are presented here</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="gp">$ </span>head demo/model/ner/en/bert-custom-model_ner_16_1e-05_4_1/test_predictions.txt
<span class="linenos"> 2</span><span class="go">This O O</span>
<span class="linenos"> 3</span><span class="go">is O O</span>
<span class="linenos"> 4</span><span class="go">not O O</span>
<span class="linenos"> 5</span><span class="go">Romeo B-PER O</span>
<span class="linenos"> 6</span><span class="go">, O O</span>
<span class="linenos"> 7</span><span class="go">he’s O O</span>
<span class="linenos"> 8</span><span class="go">some O O</span>
<span class="linenos"> 9</span><span class="go">other O O</span>
<span class="linenos">10</span><span class="go">where. O O</span>
</pre></div>
</div>
<p>The first column is the word, second column is the ground truth, and the third column is the predicted label.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="gp">$ </span>head demo/model/ner/en/bert-custom-model_ner_16_1e-05_4_1/test_results.txt
<span class="linenos">2</span><span class="go">test_loss = 1.888014554977417</span>
<span class="linenos">3</span><span class="go">test_precision = 0.0</span>
<span class="linenos">4</span><span class="go">test_recall = 0.0</span>
<span class="linenos">5</span><span class="go">test_f1 = 0.0</span>
<span class="linenos">6</span><span class="go">test_runtime = 0.0331</span>
<span class="linenos">7</span><span class="go">test_samples_per_second = 60.493</span>
<span class="linenos">8</span><span class="go">test_steps_per_second = 30.246</span>
</pre></div>
</div>
<p>The scores are bad as we have trained on a tiny corpus. Training on a larger corpus should give good results.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="clm_train.html" class="btn btn-neutral float-left" title="Training a Causal Language Model from Scratch" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="sequence_classifier_train.html" class="btn btn-neutral float-right" title="Training a Sequence Classifier" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Tejas Indulal Dhamecha, Rudra Murthy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>