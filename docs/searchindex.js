Search.setIndex({"docnames": ["clm_train", "index", "installation", "intro", "mlm_train", "modules/create_config", "modules/data_collator_for_seq_to_seq", "modules/index", "modules/run_clm", "modules/run_mlm", "modules/run_seq", "modules/run_seq_to_seq_pretrain", "modules/run_tc", "modules/tokenize_corpus", "modules/train_tokenizer", "run_clm", "run_mlm", "run_seq", "run_tc", "sequence_classifier_train", "token_classifier_train", "tokenize_corpus", "tokenizer_train", "train_tokenizer"], "filenames": ["clm_train.rst", "index.rst", "installation.rst", "intro.rst", "mlm_train.rst", "modules/create_config.rst", "modules/data_collator_for_seq_to_seq.rst", "modules/index.rst", "modules/run_clm.rst", "modules/run_mlm.rst", "modules/run_seq.rst", "modules/run_seq_to_seq_pretrain.rst", "modules/run_tc.rst", "modules/tokenize_corpus.rst", "modules/train_tokenizer.rst", "run_clm.rst", "run_mlm.rst", "run_seq.rst", "run_tc.rst", "sequence_classifier_train.rst", "token_classifier_train.rst", "tokenize_corpus.rst", "tokenizer_train.rst", "train_tokenizer.rst"], "titles": ["Training a Causal Language Model from Scratch", "Welcome to NL-FM-Toolkit\u2019s documentation!", "Installation", "Introduction", "Training a Masked Language Model from Scratch", "create_config module", "data_collator_for_seq_to_seq module", "Modules", "run_clm module", "run_mlm module", "run_seq module", "run_seq_to_seq_pretrain module", "run_tc module", "tokenize_corpus module", "train_tokenizer module", "run_clm module", "run_mlm module", "run_seq module", "run_tc module", "Training a Sequence Classifier", "Training a Sequence Labeler", "tokenize_corpus module", "Training a Tokenizer from Scratch", "train_tokenizer module"], "terms": {"we": [0, 4, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23], "ar": [0, 2, 3, 4, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20, 22], "now": [0, 4, 19, 20, 22], "readi": [0, 2, 4], "our": [0, 4, 8, 9, 10, 12, 15, 16, 17, 18, 20], "own": [0, 4, 14, 20, 23], "run": [0, 4, 19, 20, 22], "script": [0, 4, 8, 9, 15, 16, 19, 20, 22], "run_clm": [0, 1, 7], "sh": [0, 4], "transformers_cach": [0, 4], "tmp": [0, 4], "pytorch_transformers_cach": [0, 4], "pythonioencod": [0, 4], "utf": [0, 4], "8": [0, 4, 19, 20], "python": [0, 2, 4, 19, 20, 22], "src": [0, 4, 19, 20, 22], "lm": [0, 4, 8, 15, 22], "py": [0, 4, 5, 13, 14, 19, 20, 22], "model_typ": [0, 4, 7, 8, 9, 15, 16], "5": [0, 4, 8, 9, 15, 16, 19, 20], "tokenizer_nam": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20], "4": [0, 4, 19, 20], "per_device_train_batch_s": [0, 4], "per_device_eval_batch_s": [0, 4], "train_fil": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18], "1": [0, 4, 19, 20], "validation_fil": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18], "2": [0, 4, 8, 15, 19, 20], "remove_unused_column": [0, 4], "fals": [0, 4, 8, 9, 10, 12, 15, 16, 17, 18], "preprocessing_num_work": [0, 4, 7, 8, 9, 12, 15, 16, 18], "6": [0, 4, 19, 20], "pad_to_max_length": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18], "line_by_lin": [0, 4, 7, 8, 9, 15, 16], "do_train": [0, 4], "do_ev": [0, 4], "max_seq_length": [0, 7, 8, 9, 10, 12, 15, 16, 17, 18], "512": [0, 4, 9, 12, 16, 18], "num_train_epoch": [0, 4], "overwrite_output_dir": [0, 4], "output_dir": [0, 4, 19, 20], "3": [0, 2, 4, 19, 20], "report_to": [0, 4], "none": [0, 4, 8, 9, 10, 12, 14, 15, 16, 17, 18, 23], "cache_dir": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18], "evaluation_strategi": [0, 4], "step": [0, 4, 20], "logging_step": [0, 4], "10000": [0, 4], "save_step": [0, 4, 20], "save_total_limit": [0, 4], "howev": [0, 4], "test": [0, 4, 19, 20], "overrid": [0, 4], "paramet": [0, 1, 4, 14, 23], "write": [0, 4], "new": [0, 4], "file": [0, 1, 4, 5, 8, 9, 13, 14, 15, 16, 19, 23], "run_clm_test": 0, "thi": [0, 3, 4, 8, 9, 10, 14, 15, 16, 17, 19, 20, 22, 23], "follow": [0, 3, 4, 19, 20, 22], "argument": [0, 4, 7, 8, 9, 10, 12, 15, 16, 17, 18], "reduc": [0, 4], "size": [0, 4, 5, 14, 19, 20, 22], "abl": [0, 4, 10, 17], "cpu": [0, 4], "system": [0, 4], "config_overrid": [0, 4, 7, 8, 9, 15, 16], "n_embd": 0, "128": [0, 4, 10, 17], "n_head": 0, "n_layer": 0, "n_posit": 0, "256": 0, "max_train_sampl": [0, 4, 7, 8, 9, 10, 15, 16, 17], "100": [0, 4, 22], "max_eval_sampl": [0, 4, 7, 8, 9, 10, 15, 16, 17], "10": [0, 4, 19, 20], "clm": 0, "share": [0, 4], "snapshot": [0, 4], "process": [0, 4, 22], "demo": [0, 4, 19, 20, 22], "data": [0, 4, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 22], "english_sampl": [0, 4, 22], "txt": [0, 2, 4, 14, 19, 20, 22], "token": [0, 1, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23], "gpt2": [0, 5, 22], "16": [0, 4, 19, 20], "04": [0, 4], "07": [0, 4], "2022": [0, 4], "21": [0, 19, 20], "29": [0, 19, 20], "warn": [0, 4], "__main__": [0, 4], "you": [0, 2, 4, 22], "instanti": [0, 4], "config": [0, 4, 5, 8, 9, 10, 12, 15, 16, 17, 18, 19, 20], "instanc": [0, 4], "info": [0, 4], "tokenization_utils_bas": [0, 4], "1671": [0, 4], "818": 0, "didn": [0, 4], "t": [0, 4, 14, 22, 23], "find": [0, 4, 19, 20], "vocab": [0, 4, 14, 22, 23], "json": [0, 1, 4, 5, 19, 22], "won": [0, 4], "load": [0, 4, 9, 16, 20, 22], "merg": [0, 4, 22], "1740": [0, 4], "added_token": [0, 4], "special_tokens_map": [0, 4], "tokenizer_config": [0, 4], "30": [0, 19, 20], "total": [0, 4], "92m": 0, "param": [0, 4, 9, 16], "trainer": [0, 4], "1204": [0, 4], "20": [0, 4, 19, 20], "12": [0, 4, 19, 20], "42": [0, 4], "760": [0, 4], "1205": [0, 4], "num": [0, 4], "exampl": [0, 4, 20], "1895": [0, 4], "1206": [0, 4], "epoch": [0, 4, 19], "1207": [0, 4], "instantan": [0, 4], "batch": [0, 4, 19, 20], "per": [0, 4, 14, 20, 23], "devic": [0, 4], "1208": [0, 4], "w": [0, 4], "parallel": [0, 4], "distribut": [0, 4], "accumul": [0, 4], "1209": [0, 4], "gradient": [0, 4], "1210": [0, 4], "optim": [0, 4], "237": [0, 4], "loss": [0, 4, 19, 20], "9329": 0, "learning_r": [0, 4, 20], "8902953586497894e": [0, 4], "05": [0, 4, 19, 20], "0": [0, 2, 4, 9, 16, 19, 20, 22], "eval_loss": [0, 4, 19], "720452785491943": 0, "eval_runtim": [0, 4, 19], "5425": 0, "eval_samples_per_second": [0, 4, 19], "62": 0, "045": 0, "eval_steps_per_second": [0, 4, 19], "7": [0, 4, 19, 20], "76": [0, 19], "6865": 0, "805907172995782e": [0, 4], "06": [0, 4, 19, 20], "84": [0, 4], "609338760375977": 0, "8089": 0, "61": 0, "508": 0, "693": [0, 19], "complet": [0, 4], "do": [0, 4], "forget": [0, 4], "your": [0, 4, 20], "huggingfac": [0, 4, 8, 9, 14, 15, 16, 20, 23], "co": [0, 4, 8, 9, 15, 16, 20], "train_runtim": [0, 4], "220": 0, "6908": 0, "train_samples_per_second": [0, 4], "587": 0, "train_steps_per_second": [0, 4], "074": 0, "train_loss": [0, 4], "776248851405921": 0, "eval": [0, 4, 8, 9, 10, 12, 15, 16, 17, 18], "metric": [0, 4], "6093": 0, "00": [0, 22], "36": 0, "93": 0, "eval_sampl": [0, 4, 19], "51": 0, "301": 0, "416": 0, "perplex": [0, 4], "272": 0, "9637": 0, "modelcard": 0, "456": 0, "28": [0, 19, 20], "38": 0, "572": 0, "drop": 0, "result": [0, 19, 20], "doe": 0, "have": [0, 19, 20, 22], "all": [0, 22], "necessari": 0, "field": 0, "task": [0, 3, 4, 7, 10, 17], "name": [0, 4, 7, 12, 18, 19, 20, 22], "type": [0, 4, 5, 9, 14, 16, 22], "text": [0, 3, 8, 9, 15, 16, 22], "gener": 0, "The": [0, 3, 4, 14, 19, 20, 22, 23], "i": [0, 4, 8, 9, 13, 14, 15, 16, 19, 20, 22, 23], "present": [0, 4, 19, 20], "folder": [0, 4, 19, 20, 22], "fine": [0, 1, 3, 4, 8, 9, 10, 12, 15, 16, 17, 18], "tune": [0, 1, 3, 4, 8, 9, 10, 12, 15, 16, 17, 18], "l": [0, 4, 19, 20, 22], "readm": [0, 4], "md": [0, 4], "all_result": [0, 4, 19], "checkpoint": [0, 4, 8, 9, 15, 16, 19, 20], "200": [0, 4, 19, 20], "eval_result": [0, 4, 19], "pytorch_model": [0, 4, 19, 20], "bin": [0, 4, 19, 20], "trainer_st": [0, 4, 19], "train_result": [0, 4, 19], "training_arg": [0, 4, 19, 20], "introduct": 1, "instal": 1, "train": [1, 2, 3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 21, 23], "from": [1, 3, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 23], "scratch": [1, 3, 8, 9, 14, 15, 16], "creat": [1, 2, 5], "model": [1, 3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "configur": [1, 19, 20], "mask": [1, 3, 9, 16], "languag": [1, 3, 8, 9, 15, 16, 19, 20], "causal": [1, 3, 8, 15], "sequenc": [1, 3, 10, 17], "label": [1, 3, 19], "convert": 1, "conll": [1, 12, 18], "format": [1, 9, 16, 19], "classifi": 1, "hyper": 1, "us": [1, 3, 10, 13, 14, 17, 21, 22, 23], "best": 1, "modul": 1, "train_token": [1, 7, 22], "create_config": [1, 7, 22], "tokenize_corpu": [1, 7], "run_mlm": [1, 4, 7], "run_seq_to_seq_pretrain": [1, 7], "run_tc": [1, 7], "run_seq": [1, 7], "data_collator_for_seq_to_seq": [1, 7], "index": [1, 9, 16], "search": [1, 19, 20], "page": 1, "git": 2, "clone": 2, "http": [2, 8, 9, 15, 16, 20, 22], "github": 2, "com": 2, "ibm": 2, "nl": [2, 3], "fm": [2, 3], "toolkit": [2, 3], "cd": 2, "conda": 2, "n": 2, "nlpworkspac": 2, "9": [2, 19, 20], "activ": 2, "pip": 2, "r": 2, "requir": [2, 22], "And": 2, "go": [2, 8, 9, 10, 12, 15, 16, 17, 18], "take": [2, 14, 23], "look": [2, 19, 20, 22], "quickstart": 2, "familiar": 2, "yourself": 2, "main": [2, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 21, 23], "workflow": 2, "repositori": [3, 22], "support": 3, "exist": 3, "pre": [3, 5, 9, 13, 14, 16, 19, 20, 21, 22, 23], "like": [3, 19], "po": [3, 20], "ner": [3, 12, 18, 19, 20], "etc": [3, 19, 20], "classif": [3, 10, 17], "sentiment": [3, 19], "analysi": 3, "encod": 3, "onli": [3, 19, 20], "bert": [3, 4, 9, 12, 16, 18, 19, 20], "whole": 3, "word": [3, 9, 14, 16, 20, 22, 23], "auto": 3, "regress": 3, "gpt": [3, 8, 15], "decod": 3, "mbart": 3, "mt5": [3, 5], "denois": 3, "object": [3, 8, 9, 10, 12, 15, 16, 17, 18], "portal": 3, "provid": [3, 19, 20, 22], "detail": 3, "document": 3, "It": 3, "describ": 3, "how": 3, "pytorch": 3, "project": [3, 22], "work": 3, "run_mlm_test": 4, "hidden_s": 4, "intermediate_s": 4, "num_attention_head": 4, "num_hidden_lay": 4, "max_position_embed": 4, "mlm": [4, 19, 20], "41": 4, "bertconfig": 4, "attention_probs_dropout_prob": 4, "classifier_dropout": 4, "null": 4, "hidden_act": 4, "gelu": 4, "hidden_dropout_prob": 4, "initializer_rang": 4, "02": 4, "layer_norm_ep": 4, "1e": [4, 19, 20], "pad_token_id": 4, "position_embedding_typ": 4, "absolut": 4, "transformers_vers": 4, "14": [4, 19, 20], "type_vocab_s": 4, "use_cach": 4, "true": [4, 8, 9, 10, 15, 16, 17], "vocab_s": [4, 5, 14, 22], "30522": 4, "922": 4, "923": 4, "59m": 4, "1333": 4, "023196220397949": 4, "132": 4, "1578": 4, "339": 4, "793": 4, "9755": 4, "97206974029541": 4, "81": 4, "7657": 4, "23": [4, 19, 20], "176": 4, "899": 4, "533": 4, "2352": 4, "554": 4, "444": 4, "034984540335739": 4, "035": 4, "08": [4, 20], "53": 4, "train_sampl": 4, "27": [4, 19, 20], "evalu": [4, 20], "fill": [4, 9, 16], "9712": 4, "01": 4, "24": [4, 19, 20], "94": 4, "22": [4, 19, 20], "308": 4, "79": 4, "391": 4, "9806": 4, "arg": [5, 10, 12, 14, 17, 18, 23], "sourc": [5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 21, 23], "usag": [5, 13, 14], "h": [5, 13, 14], "path": [5, 9, 13, 14, 16, 20, 22], "led": 5, "where": [5, 13, 14, 20, 22], "default": [5, 13, 14, 22], "gpt2_event_token": 5, "possibl": [5, 14], "choic": [5, 14], "vocabulari": [5, 14, 23], "30000": [5, 14], "add_vocab_from_fil": [7, 14, 23], "datatrainingargu": [7, 8, 9, 10, 12, 15, 16, 17, 18], "block_siz": [7, 8, 15], "dataset_config_nam": [7, 8, 9, 10, 12, 15, 16, 17, 18], "dataset_nam": [7, 8, 9, 10, 12, 15, 16, 17, 18], "keep_linebreak": [7, 8, 9, 15, 16], "overwrite_cach": [7, 8, 9, 10, 12, 15, 16, 17, 18], "test_fil": [7, 8, 9, 10, 12, 15, 16, 17, 18], "validation_split_percentag": [7, 8, 9, 15, 16], "modelargu": [7, 8, 9, 10, 12, 15, 16, 17, 18], "config_nam": [7, 8, 9, 10, 12, 15, 16, 17, 18, 20], "model_name_or_path": [7, 8, 9, 10, 12, 15, 16, 17, 18], "model_revis": [7, 8, 9, 10, 15, 16, 17], "use_auth_token": [7, 8, 9, 10, 12, 15, 16, 17, 18], "use_fast_token": [7, 8, 9, 10, 15, 16, 17], "mlm_probabl": [7, 9, 16], "freeze_token_emb": [7, 9, 16], "pretrained_token_emb": [7, 9, 16], "read_txt_embed": [7, 9, 16], "early_stop": [7, 10, 12, 17, 18], "label_column_nam": [7, 12, 18], "task_nam": [7, 10, 12, 17, 18, 19, 20], "text_column_nam": [7, 12, 18], "log_dir": [7, 10, 12, 17, 18, 19, 20], "use_fast": [7, 12, 18], "max_predict_sampl": [7, 10, 17], "taskargu": [7, 10, 17], "librari": [8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 23], "ctrl": [8, 15], "dataset": [8, 9, 15, 16, 20], "here": [8, 9, 15, 16, 19, 20, 22], "full": [8, 9, 15, 16], "list": [8, 9, 15, 16], "hub": [8, 9, 15, 16], "can": [8, 9, 10, 15, 16, 17, 19, 20], "filter": [8, 9, 15, 16], "class": [8, 9, 10, 12, 15, 16, 17, 18, 19], "option": [8, 9, 10, 12, 14, 15, 16, 17, 18, 23], "str": [8, 9, 10, 12, 14, 15, 16, 17, 18, 23], "int": [8, 9, 10, 12, 15, 16, 17, 18], "1024": [8, 15], "bool": [8, 9, 10, 12, 15, 16, 17, 18], "base": [8, 9, 10, 12, 15, 16, 17, 18], "pertain": [8, 9, 10, 12, 15, 16, 17, 18], "what": [8, 9, 10, 12, 15, 16, 17, 18], "input": [8, 9, 10, 12, 14, 15, 16, 17, 18, 23], "which": [8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 23], "albert": [9, 16], "roberta": [9, 12, 16, 18], "float": [9, 16], "15": [9, 16, 19, 20], "file_nam": [9, 16], "embed": [9, 16], "filenam": [9, 16, 19, 20], "glove": [9, 16], "return": [9, 14, 16, 23], "wordembed": [9, 16], "numpi": [9, 16], "nd": [9, 16], "arrai": [9, 16], "dictionari": [9, 16], "dict": [9, 16], "map": [9, 16], "finetun": [10, 17], "hfargumentpars": [10, 17], "turn": [10, 17], "argpars": [10, 17], "specifi": [10, 17, 20], "them": [10, 17], "command": [10, 17, 19, 20], "line": [10, 14, 17, 19, 20, 23], "entiti": [12, 18, 20], "recognit": [12, 18], "2003": [12, 18], "code": [13, 14, 19, 20, 21, 23], "an": [13, 20, 21], "hous": [13, 14, 21, 23], "corpu": [13, 14, 19, 20, 21, 22, 23], "corpora": [13, 14, 21, 23], "input_fil": [13, 14, 22], "model_path": 13, "output": [13, 20], "save": [13, 14, 20], "temp": 13, "sub": [14, 23], "transform": [14, 23], "contain": [14, 19, 20, 23], "": [14, 20, 23], "shouldn": [14, 23], "split": [14, 23], "vocab_fil": [14, 23], "function": [14, 23], "read": [14, 23], "add": [14, 23], "should": [14, 19, 20, 23], "everi": [14, 20, 23], "autotoken": [14, 22, 23], "just": [14, 23], "could": [14, 20, 23], "also": [14, 19, 23], "ani": [14, 23], "need": [14, 20, 22, 23], "subword": [14, 23], "tokenizer_typ": [14, 22], "byte": 14, "wordpiec": [14, 22], "ha": 14, "byte_token": 14, "let": [19, 20, 22], "u": [19, 20, 22], "short": [19, 20, 22], "tutori": [19, 20, 22], "For": [19, 20, 22], "sampl": [19, 20, 22], "dev": [19, 20], "tab": [19, 20], "separ": [19, 20], "snippet": [19, 20, 22], "first": [19, 20], "sentenc": [19, 20], "column": [19, 20], "second": [19, 20], "cat": [19, 20], "movi": 19, "hate": 19, "wa": 19, "good": [19, 20], "same": [19, 20], "mention": [19, 20], "abov": [19, 20], "select": [19, 20], "valu": [19, 20], "monitor": [19, 20], "accuraci": [19, 20], "f1": [19, 20], "score": [19, 20], "set": [19, 20], "perform": [19, 20], "grid": [19, 20], "over": [19, 20], "learn": [19, 20], "rate": [19, 20], "32": [19, 20], "3e": [19, 20], "13e": [19, 20], "5e": [19, 20], "sequenceclassifi": 19, "helper_script": [19, 20], "tune_hyper_paramet": [19, 20], "data_dir": [19, 20], "configuration_nam": [19, 20], "custom": [19, 20], "model_nam": [19, 20], "log": [19, 20], "aim": [19, 20], "track": [19, 20], "experi": [19, 20], "get_best_hyper_parameter_and_train": [19, 20], "batchsiz": [19, 20], "learningr": [19, 20], "666667": 19, "001": [19, 20], "0001": [19, 20], "003": [19, 20], "0003": [19, 20], "005": [19, 20], "0005": [19, 20], "11": [19, 20], "13": [19, 20], "17": [19, 20], "18": [19, 20], "19": [19, 20], "25": [19, 20], "26": [19, 20], "31": [19, 20], "33": [19, 20], "34": [19, 20], "35": [19, 20], "6666666666666666": 19, "differ": [19, 20], "random": [19, 20], "seed": [19, 20], "found": [19, 20], "lh": [19, 20], "grep": [19, 20], "d": [19, 20], "awk": [19, 20], "print": [19, 20], "model_sentiment_16_0": 19, "001_4_1": 19, "001_4_2": 19, "001_4_3": 19, "001_4_4": 19, "001_4_5": 19, "386b": 19, "700b": 19, "219b": 19, "41b": 19, "predict_results_senti": 19, "6m": [19, 20], "96b": [19, 20], "48b": 19, "test_predict": [19, 20], "147b": 19, "test_result": [19, 20], "187b": 19, "808b": 19, "9k": [19, 20], "predict": [19, 20], "similarli": [19, 20], "respect": [19, 20], "jsom": 19, "head": [19, 20, 22], "en": [19, 20], "model_ner_16_1": [19, 20], "05_4_1": [19, 20], "eval_f1": 19, "7115099430084229": 19, "0788": 19, "159": 19, "bad": [19, 20], "tini": [19, 20], "larger": [19, 20], "give": [19, 20, 22], "taken": 20, "wikiann": 20, "csv": 20, "o": 20, "romeo": [20, 22], "b": 20, "he": 20, "some": 20, "other": [20, 22], "plantain": 20, "leaf": 20, "excel": 20, "either": 20, "space": 20, "success": 20, "empti": 20, "so": 20, "easili": 20, "convers": 20, "tokenclassifi": 20, "conll_to_json_convert": 20, "column_numb": 20, "number": 20, "directli": 20, "train_tc": 20, "batch_siz": 20, "train_step": 20, "maximum": 20, "eval_step": 20, "after": 20, "max_seq_len": 20, "length": 20, "trim": 20, "perform_grid_search": 20, "would": 20, "store": 20, "eval_onli": 20, "0833333": 20, "08333333333333334": 20, "05_4_2": 20, "05_4_3": 20, "05_4_4": 20, "05_4_5": 20, "224b": 20, "goat": 20, "884b": 20, "417b": 20, "dev_predict": 20, "188b": 20, "dev_result": 20, "262b": 20, "169b": 20, "ground": 20, "truth": 20, "third": 20, "test_loss": 20, "888014554977417": 20, "test_precis": 20, "test_recal": 20, "test_f1": 20, "test_runtim": 20, "0331": 20, "test_samples_per_second": 20, "60": 20, "493": 20, "test_steps_per_second": 20, "246": 20, "get_command_line_arg": [21, 23], "program": 22, "root": 22, "To": 22, "gutenberg": 22, "ebook": 22, "juliet": 22, "william": 22, "shakespear": 22, "anyon": 22, "anywher": 22, "unit": 22, "state": 22, "most": 22, "part": 22, "world": 22, "cost": 22, "almost": 22, "restrict": 22, "whatsoev": 22, "mai": 22, "copi": 22, "awai": 22, "re": 22, "under": 22, "term": 22, "licens": 22, "includ": 22, "onlin": 22, "www": 22, "org": 22, "If": 22, "locat": 22, "check": 22, "law": 22, "countri": 22, "befor": 22, "wc": 22, "2136": 22, "10152": 22, "56796": 22, "extract": 22, "plai": 22, "cach": 22, "epub": 22, "1513": 22, "pg1513": 22, "around": 22, "500": 22, "smaller": 22, "due": 22, "being": 22, "small": 22, "mo": 22, "4252": 22, "count": 22, "pair": 22, "comput": 22, "387": 22, "insid": 22, "By": 22, "doesn": 22, "from_pretrain": 22}, "objects": {"": [[5, 0, 0, "-", "create_config"], [15, 0, 0, "-", "run_clm"], [16, 0, 0, "-", "run_mlm"], [17, 0, 0, "-", "run_seq"], [18, 0, 0, "-", "run_tc"], [21, 0, 0, "-", "tokenize_corpus"], [23, 0, 0, "-", "train_tokenizer"]], "create_config": [[5, 1, 1, "", "main"]], "run_clm": [[15, 2, 1, "", "DataTrainingArguments"], [15, 2, 1, "", "ModelArguments"], [15, 1, 1, "", "main"]], "run_clm.DataTrainingArguments": [[15, 3, 1, "", "block_size"], [15, 3, 1, "", "dataset_config_name"], [15, 3, 1, "", "dataset_name"], [15, 3, 1, "", "keep_linebreaks"], [15, 3, 1, "", "line_by_line"], [15, 3, 1, "", "max_eval_samples"], [15, 3, 1, "", "max_seq_length"], [15, 3, 1, "", "max_train_samples"], [15, 3, 1, "", "overwrite_cache"], [15, 3, 1, "", "pad_to_max_length"], [15, 3, 1, "", "preprocessing_num_workers"], [15, 3, 1, "", "test_file"], [15, 3, 1, "", "train_file"], [15, 3, 1, "", "validation_file"], [15, 3, 1, "", "validation_split_percentage"]], "run_clm.ModelArguments": [[15, 3, 1, "", "cache_dir"], [15, 3, 1, "", "config_name"], [15, 3, 1, "", "config_overrides"], [15, 3, 1, "", "model_name_or_path"], [15, 3, 1, "", "model_revision"], [15, 3, 1, "", "model_type"], [15, 3, 1, "", "tokenizer_name"], [15, 3, 1, "", "use_auth_token"], [15, 3, 1, "", "use_fast_tokenizer"]], "run_mlm": [[16, 2, 1, "", "DataTrainingArguments"], [16, 2, 1, "", "ModelArguments"], [16, 1, 1, "", "main"], [16, 1, 1, "", "read_txt_embeddings"]], "run_mlm.DataTrainingArguments": [[16, 3, 1, "", "dataset_config_name"], [16, 3, 1, "", "dataset_name"], [16, 3, 1, "", "keep_linebreaks"], [16, 3, 1, "", "line_by_line"], [16, 3, 1, "", "max_eval_samples"], [16, 3, 1, "", "max_seq_length"], [16, 3, 1, "", "max_train_samples"], [16, 3, 1, "", "mlm_probability"], [16, 3, 1, "", "overwrite_cache"], [16, 3, 1, "", "pad_to_max_length"], [16, 3, 1, "", "preprocessing_num_workers"], [16, 3, 1, "", "test_file"], [16, 3, 1, "", "train_file"], [16, 3, 1, "", "validation_file"], [16, 3, 1, "", "validation_split_percentage"]], "run_mlm.ModelArguments": [[16, 3, 1, "", "cache_dir"], [16, 3, 1, "", "config_name"], [16, 3, 1, "", "config_overrides"], [16, 3, 1, "", "freeze_token_embed"], [16, 3, 1, "", "model_name_or_path"], [16, 3, 1, "", "model_revision"], [16, 3, 1, "", "model_type"], [16, 3, 1, "", "pretrained_token_embed"], [16, 3, 1, "", "tokenizer_name"], [16, 3, 1, "", "use_auth_token"], [16, 3, 1, "", "use_fast_tokenizer"]], "run_seq": [[17, 2, 1, "", "DataTrainingArguments"], [17, 2, 1, "", "ModelArguments"], [17, 2, 1, "", "TaskArguments"], [17, 1, 1, "", "main"]], "run_seq.DataTrainingArguments": [[17, 3, 1, "", "dataset_config_name"], [17, 3, 1, "", "dataset_name"], [17, 3, 1, "", "max_eval_samples"], [17, 3, 1, "", "max_predict_samples"], [17, 3, 1, "", "max_seq_length"], [17, 3, 1, "", "max_train_samples"], [17, 3, 1, "", "overwrite_cache"], [17, 3, 1, "", "pad_to_max_length"], [17, 3, 1, "", "task_name"], [17, 3, 1, "", "test_file"], [17, 3, 1, "", "train_file"], [17, 3, 1, "", "validation_file"]], "run_seq.ModelArguments": [[17, 3, 1, "", "cache_dir"], [17, 3, 1, "", "config_name"], [17, 3, 1, "", "log_dir"], [17, 3, 1, "", "model_name_or_path"], [17, 3, 1, "", "model_revision"], [17, 3, 1, "", "tokenizer_name"], [17, 3, 1, "", "use_auth_token"], [17, 3, 1, "", "use_fast_tokenizer"]], "run_seq.TaskArguments": [[17, 3, 1, "", "early_stop"], [17, 3, 1, "", "task"]], "run_tc": [[18, 2, 1, "", "DataTrainingArguments"], [18, 2, 1, "", "ModelArguments"], [18, 1, 1, "", "main"]], "run_tc.DataTrainingArguments": [[18, 3, 1, "", "dataset_config_name"], [18, 3, 1, "", "dataset_name"], [18, 3, 1, "", "early_stop"], [18, 3, 1, "", "label_column_name"], [18, 3, 1, "", "max_seq_length"], [18, 3, 1, "", "overwrite_cache"], [18, 3, 1, "", "pad_to_max_length"], [18, 3, 1, "", "preprocessing_num_workers"], [18, 3, 1, "", "task_name"], [18, 3, 1, "", "test_file"], [18, 3, 1, "", "text_column_name"], [18, 3, 1, "", "train_file"], [18, 3, 1, "", "validation_file"]], "run_tc.ModelArguments": [[18, 3, 1, "", "cache_dir"], [18, 3, 1, "", "config_name"], [18, 3, 1, "", "log_dir"], [18, 3, 1, "", "model_name_or_path"], [18, 3, 1, "", "tokenizer_name"], [18, 3, 1, "", "use_auth_token"], [18, 3, 1, "", "use_fast"]], "tokenize_corpus": [[21, 1, 1, "", "get_command_line_args"], [21, 1, 1, "", "main"]], "train_tokenizer": [[23, 1, 1, "", "add_vocab_from_file"], [23, 1, 1, "", "get_command_line_args"], [23, 1, 1, "", "main"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"]}, "titleterms": {"train": [0, 4, 19, 20, 22], "causal": 0, "languag": [0, 4], "model": [0, 4, 22], "from": [0, 4, 22], "scratch": [0, 4, 22], "welcom": 1, "nl": 1, "fm": 1, "toolkit": 1, "": 1, "document": 1, "get": 1, "start": 1, "script": 1, "indic": 1, "tabl": 1, "instal": 2, "introduct": 3, "mask": 4, "create_config": 5, "modul": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23], "name": [5, 13, 14], "argument": [5, 13, 14], "data_collator_for_seq_to_seq": 6, "run_clm": [8, 15], "run_mlm": [9, 16], "run_seq": [10, 17], "run_seq_to_seq_pretrain": 11, "run_tc": [12, 18], "tokenize_corpu": [13, 21], "train_token": [14, 23], "sequenc": [19, 20], "classifi": [19, 20], "hyper": [19, 20], "paramet": [19, 20], "tune": [19, 20], "fine": [19, 20], "us": [19, 20], "best": [19, 20], "label": 20, "convert": 20, "conll": 20, "file": [20, 22], "json": 20, "format": 20, "token": [20, 22], "creat": 22, "configur": 22}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Training a Causal Language Model from Scratch": [[0, "training-a-causal-language-model-from-scratch"]], "Welcome to NL-FM-Toolkit\u2019s documentation!": [[1, "welcome-to-nl-fm-toolkit-s-documentation"]], "Getting Started:": [[1, null]], "Scripts": [[1, null]], "Indices and tables": [[1, "indices-and-tables"]], "Installation": [[2, "installation"]], "Introduction": [[3, "introduction"]], "Training a Masked Language Model from Scratch": [[4, "training-a-masked-language-model-from-scratch"]], "create_config module": [[5, "module-create_config"]], "Named Arguments": [[5, "named-arguments"], [13, "named-arguments"], [14, "named-arguments"]], "run_clm module": [[8, "module-run_clm"], [15, "module-run_clm"]], "run_mlm module": [[9, "module-run_mlm"], [16, "module-run_mlm"]], "run_seq module": [[10, "module-run_seq"], [17, "module-run_seq"]], "run_tc module": [[12, "module-run_tc"], [18, "module-run_tc"]], "tokenize_corpus module": [[13, "module-tokenize_corpus"], [21, "module-tokenize_corpus"]], "train_tokenizer module": [[14, "module-train_tokenizer"], [23, "module-train_tokenizer"]], "Training a Sequence Classifier": [[19, "training-a-sequence-classifier"]], "Hyper-Parameter Tuning": [[19, "hyper-parameter-tuning"], [20, "hyper-parameter-tuning"]], "Fine-Tuning using best Hyper-Parameter": [[19, "fine-tuning-using-best-hyper-parameter"], [20, "fine-tuning-using-best-hyper-parameter"]], "Training a Sequence Labeler": [[20, "training-a-sequence-labeler"]], "Convert CoNLL file to JSON format": [[20, "convert-conll-file-to-json-format"]], "Training a Token classifier": [[20, "training-a-token-classifier"]], "Training a Tokenizer from Scratch": [[22, "training-a-tokenizer-from-scratch"]], "Creating Model Configuration File": [[22, "creating-model-configuration-file"]], "data_collator_for_seq_to_seq module": [[6, "data-collator-for-seq-to-seq-module"]], "Modules": [[7, "modules"]], "run_seq_to_seq_pretrain module": [[11, "run-seq-to-seq-pretrain-module"]]}, "indexentries": {}})