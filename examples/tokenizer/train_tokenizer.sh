python src/tokenizer/train_tokenizer.py \
     --input_file demo/data/lm/english_sample.txt \
     --name demo/model/tokenizer/ \
     --tokenizer_type wordpiece \
     --vocab_size 500